{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem', 'ipsum', 'dolor', 'sit', 'amet', ',', 'consectetur', 'adipiscing', 'elit', '.', 'Suspendisse', 'dignissim', 'pretium', 'lectus', ',', 'dignissim', 'molestie', 'lacus', 'viverra', 'eu', '.', 'Sed', 'venenatis', 'mauris', 'vel', 'tellus', 'ornare', 'tempus', '.', 'Aenean', 'in', 'laoreet', 'eros', '.', 'Duis', 'feugiat', ',', 'elit', 'non', 'maximus', 'auctor', ',', 'sapien', 'ex', 'vehicula', 'nulla', ',', 'sit', 'amet', 'cursus', 'dui', 'orci', 'ut', 'tellus', '.', 'Duis', 'cursus', 'volutpat', 'convallis', '.', 'Maecenas', 'posuere', 'tortor', 'enim', '.', 'Maecenas', 'vulputate', 'mauris', 'placerat', ',', 'ultrices', 'odio', 'in', ',', 'condimentum', 'arcu', '.', 'Cras', 'sollicitudin', 'mauris', 'at', 'justo', 'tristique', ',', 'at', 'condimentum', 'ante', 'ornare', '.', 'Vivamus', 'cursus', 'sapien', 'et', 'sapien', 'mattis', 'tristique', '.', 'Duis', 'et', 'tincidunt', 'ipsum', '.', 'Integer', 'interdum', 'vulputate', 'lorem', ',', 'sed', 'hendrerit', 'felis', 'pulvinar', 'ut', '.', 'Vivamus', 'non', 'lectus', 'bibendum', 'imperdiet', 'pretium', 'vel', 'in', 'libero', '.', 'Aliquam', 'semper', 'tincidunt', 'turpis', 'et', 'feugiat', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "#https://www.lipsum.com/feed/html\n",
    "text='''Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
    "Suspendisse dignissim pretium lectus, \n",
    "dignissim molestie lacus viverra eu. \n",
    "Sed venenatis mauris vel tellus ornare tempus. \n",
    "Aenean in laoreet eros. Duis feugiat, elit non maximus\n",
    "auctor, sapien ex vehicula nulla, sit amet cursus dui \n",
    "orci ut tellus. Duis cursus volutpat convallis. \n",
    "Maecenas posuere tortor enim. Maecenas vulputate \n",
    "mauris placerat, ultrices odio in, condimentum arcu. \n",
    "Cras sollicitudin mauris at justo tristique, at \n",
    "condimentum ante ornare. Vivamus cursus sapien et \n",
    "sapien mattis tristique. Duis et tincidunt ipsum. \n",
    "Integer interdum vulputate lorem, sed hendrerit \n",
    "felis pulvinar ut. Vivamus non lectus bibendum \n",
    "imperdiet pretium vel in libero. Aliquam semper \n",
    "tincidunt turpis et feugiat.'''\n",
    "print(word_tokenize(text))\n",
    "#keras has a tokenzier\n",
    "#boundary of words can be complicated, but in english this is not as hard as some other langauges\n",
    "#handling symbols can also be hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gutenberg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiw = nltk.corpus.gutenberg.words('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Alice', \"'\", 's', 'Adventures', 'in', ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words: ['they', 'then', 'here', 'their', 'yourselves', 'through', 'you', \"couldn't\", 'which', 'own']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alm0708\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# stop words are common words that have low information value in text\n",
    "#we generally get rid of stop words\n",
    "nltk.download('stopwords')\n",
    "sw = set(nltk.corpus.stopwords.words('english'))\n",
    "print(\"Stop words: \" + str(list(sw)[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', ']'], ['CHAPTER', 'I', '.'], ['Down', 'the', 'Rabbit', '-', 'Hole'], ['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'\", 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', \",'\", 'thought', 'Alice', \"'\", 'without', 'pictures', 'or', 'conversation', \"?'\"], ['So', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', '),', 'whether', 'the', 'pleasure', 'of', 'making', 'a', 'daisy', '-', 'chain', 'would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and', 'picking', 'the', 'daisies', ',', 'when', 'suddenly', 'a', 'White', 'Rabbit', 'with', 'pink', 'eyes', 'ran', 'close', 'by', 'her', '.'], ['There', 'was', 'nothing', 'so', 'VERY', 'remarkable', 'in', 'that', ';', 'nor', 'did', 'Alice', 'think', 'it', 'so', 'VERY', 'much', 'out', 'of', 'the', 'way', 'to', 'hear', 'the', 'Rabbit', 'say', 'to', 'itself', ',', \"'\", 'Oh', 'dear', '!'], ['Oh', 'dear', '!'], ['I', 'shall', 'be', 'late', \"!'\"], ['(', 'when', 'she', 'thought', 'it', 'over', 'afterwards', ',', 'it', 'occurred', 'to', 'her', 'that', 'she', 'ought', 'to', 'have', 'wondered', 'at', 'this', ',', 'but', 'at', 'the', 'time', 'it', 'all', 'seemed', 'quite', 'natural', ');', 'but', 'when', 'the', 'Rabbit', 'actually', 'TOOK', 'A', 'WATCH', 'OUT', 'OF', 'ITS', 'WAISTCOAT', '-', 'POCKET', ',', 'and', 'looked', 'at', 'it', ',', 'and', 'then', 'hurried', 'on', ',', 'Alice', 'started', 'to', 'her', 'feet', ',', 'for', 'it', 'flashed', 'across', 'her', 'mind', 'that', 'she', 'had', 'never', 'before', 'seen', 'a', 'rabbit', 'with', 'either', 'a', 'waistcoat', '-', 'pocket', ',', 'or', 'a', 'watch', 'to', 'take', 'out', 'of', 'it', ',', 'and', 'burning', 'with', 'curiosity', ',', 'she', 'ran', 'across', 'the', 'field', 'after', 'it', ',', 'and', 'fortunately', 'was', 'just', 'in', 'time', 'to', 'see', 'it', 'pop', 'down', 'a', 'large', 'rabbit', '-', 'hole', 'under', 'the', 'hedge', '.'], ['In', 'another', 'moment', 'down', 'went', 'Alice', 'after', 'it', ',', 'never', 'once', 'considering', 'how', 'in', 'the', 'world', 'she', 'was', 'to', 'get', 'out', 'again', '.']]\n"
     ]
    }
   ],
   "source": [
    "#stop words are all lowercase. You want to do this too\n",
    "#nltk.download('punkt')\n",
    "text_sentences = nltk.corpus.gutenberg.sents(\"carroll-alice.txt\")[:10]\n",
    "print(text_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Alice', \"'\", 'Adventures', 'Wonderland', 'Lewis', 'Carroll', '1865', ']']\n",
      "['CHAPTER', '.']\n",
      "['Rabbit', '-', 'Hole']\n",
      "['Alice', 'beginning', 'get', 'tired', 'sitting', 'sister', 'bank', ',', 'nothing', ':', 'twice', 'peeped', 'book', 'sister', 'reading', ',', 'pictures', 'conversations', ',', \"'\", 'use', 'book', \",'\", 'thought', 'Alice', \"'\", 'without', 'pictures', 'conversation', \"?'\"]\n",
      "['considering', 'mind', '(', 'well', 'could', ',', 'hot', 'day', 'made', 'feel', 'sleepy', 'stupid', '),', 'whether', 'pleasure', 'making', 'daisy', '-', 'chain', 'would', 'worth', 'trouble', 'getting', 'picking', 'daisies', ',', 'suddenly', 'White', 'Rabbit', 'pink', 'eyes', 'ran', 'close', '.']\n",
      "['nothing', 'remarkable', ';', 'Alice', 'think', 'much', 'way', 'hear', 'Rabbit', 'say', ',', \"'\", 'Oh', 'dear', '!']\n",
      "['Oh', 'dear', '!']\n",
      "['shall', 'late', \"!'\"]\n",
      "['(', 'thought', 'afterwards', ',', 'occurred', 'ought', 'wondered', ',', 'time', 'seemed', 'quite', 'natural', ');', 'Rabbit', 'actually', 'TOOK', 'WATCH', 'WAISTCOAT', '-', 'POCKET', ',', 'looked', ',', 'hurried', ',', 'Alice', 'started', 'feet', ',', 'flashed', 'across', 'mind', 'never', 'seen', 'rabbit', 'either', 'waistcoat', '-', 'pocket', ',', 'watch', 'take', ',', 'burning', 'curiosity', ',', 'ran', 'across', 'field', ',', 'fortunately', 'time', 'see', 'pop', 'large', 'rabbit', '-', 'hole', 'hedge', '.']\n",
      "['another', 'moment', 'went', 'Alice', ',', 'never', 'considering', 'world', 'get', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['another',\n",
       " 'moment',\n",
       " 'went',\n",
       " 'Alice',\n",
       " ',',\n",
       " 'never',\n",
       " 'considering',\n",
       " 'world',\n",
       " 'get',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in text_sentences:\n",
    "    filtered_list = [w for w in sentence if w.lower() not in sw]\n",
    "    print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865']\n",
      "['CHAPTER', 'I']\n",
      "['Down', 'the', 'Rabbit', 'Hole']\n",
      "['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', 'and', 'of', 'having', 'nothing', 'to', 'do', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', 'thought', 'Alice', 'without', 'pictures', 'or', 'conversation']\n",
      "['So', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', 'as', 'well', 'as', 'she', 'could', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', 'whether', 'the', 'pleasure', 'of', 'making', 'a', 'daisy', 'chain', 'would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and', 'picking', 'the', 'daisies', 'when', 'suddenly', 'a', 'White', 'Rabbit', 'with', 'pink', 'eyes', 'ran', 'close', 'by', 'her']\n",
      "['There', 'was', 'nothing', 'so', 'VERY', 'remarkable', 'in', 'that', 'nor', 'did', 'Alice', 'think', 'it', 'so', 'VERY', 'much', 'out', 'of', 'the', 'way', 'to', 'hear', 'the', 'Rabbit', 'say', 'to', 'itself', 'Oh', 'dear']\n",
      "['Oh', 'dear']\n",
      "['I', 'shall', 'be', 'late']\n",
      "['when', 'she', 'thought', 'it', 'over', 'afterwards', 'it', 'occurred', 'to', 'her', 'that', 'she', 'ought', 'to', 'have', 'wondered', 'at', 'this', 'but', 'at', 'the', 'time', 'it', 'all', 'seemed', 'quite', 'natural', 'but', 'when', 'the', 'Rabbit', 'actually', 'TOOK', 'A', 'WATCH', 'OUT', 'OF', 'ITS', 'WAISTCOAT', 'POCKET', 'and', 'looked', 'at', 'it', 'and', 'then', 'hurried', 'on', 'Alice', 'started', 'to', 'her', 'feet', 'for', 'it', 'flashed', 'across', 'her', 'mind', 'that', 'she', 'had', 'never', 'before', 'seen', 'a', 'rabbit', 'with', 'either', 'a', 'waistcoat', 'pocket', 'or', 'a', 'watch', 'to', 'take', 'out', 'of', 'it', 'and', 'burning', 'with', 'curiosity', 'she', 'ran', 'across', 'the', 'field', 'after', 'it', 'and', 'fortunately', 'was', 'just', 'in', 'time', 'to', 'see', 'it', 'pop', 'down', 'a', 'large', 'rabbit', 'hole', 'under', 'the', 'hedge']\n",
      "['In', 'another', 'moment', 'down', 'went', 'Alice', 'after', 'it', 'never', 'once', 'considering', 'how', 'in', 'the', 'world', 'she', 'was', 'to', 'get', 'out', 'again']\n"
     ]
    }
   ],
   "source": [
    "#take one or two characters that should be eliminated, and write a list comprehension to remove them from the filtered_list\n",
    "#you can use punkt to do that or you can do it \"manually\"\n",
    "for sentence in text_sentences:\n",
    "    filtered_list = [w for w in sentence if w.lower() not in sw]\n",
    "    new_filtered_list = [word for word in sentence if word.isalnum()]\n",
    "    print(new_filtered_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worrier'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming - finding root words\n",
    "# overstemming - words are over truncated car vs caring \n",
    "#understemming (false negative) - \"alumnus\" -> \"alumnu\"\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language = \"english\")\n",
    "word = 'worrier'\n",
    "stemmer.stem(word)\n",
    "#fun fact: Google adopted word stemming in 2003. Prior to that, searching \"fish\"\n",
    "# would not have given results for \"fishing\" or \"fishes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worrier\n"
     ]
    }
   ],
   "source": [
    "#lemmatization - finding the form of a word thats related in the dictionary. \n",
    "#the process for calculating lemmas is more complicated than stemming\n",
    "#lemmatization considers the context and converts the word to a \"meaningful base form\" (a lemma)\n",
    "#a word can have multiple lemmas\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('worrier'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\alm0708\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#nltk.download('vader_lexicon')\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.006, 'neu': 0.983, 'pos': 0.012, 'compound': 0.4019}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'Etymology and naming\\nThe origin of the English word \\'cat\\', Old English catt, is thought to be the Late Latin word cattus, which was first used at the beginning of the 6th century.[20] It was suggested that the word \\'cattus\\' is derived from an Egyptian precursor of Coptic ϣⲁⲩ šau, \"tomcat\", or its feminine form suffixed with -t.[21] The Late Latin word may be derived from another Afro-Asiatic[22] or Nilo-Saharan language. The Nubian word kaddîska \"wildcat\" and Nobiin kadīs are possible sources or cognates.[23] The Nubian word may be a loan from Arabic قَطّ\\u200e qaṭṭ ~ قِطّ qiṭṭ. It is \"equally likely that the forms might derive from an ancient Germanic word, imported into Latin and thence to Greek and to Syriac and Arabic\".[24] The word may be derived from Germanic and Northern European languages, and ultimately be borrowed from Uralic, cf. Northern Sami gáđfi, \"female stoat\", and Hungarian hölgy, \"stoat\"; from Proto-Uralic *käďwä, \"female (of a furred animal)\".[25]\\n\\nThe English puss, extended as pussy and pussycat, is attested from the 16th century and may have been introduced from Dutch poes or from Low German puuskatte, related to Swedish kattepus, or Norwegian pus, pusekatt. Similar forms exist in Lithuanian puižė and Irish puisín or puiscín. The etymology of this word is unknown, but it may have simply arisen from a sound used to attract a cat.[26][27]\\n\\nA male cat is called a tom or tomcat[28] (or a gib,[29] if neutered). An unspayed female is called a queen,[30] especially in a cat-breeding context. A juvenile cat is referred to as a kitten. In Early Modern English, the word kitten was interchangeable with the now-obsolete word catling.[31] A group of cats can be referred to as a clowder or a glaring.[32]\\n',\n",
       "  'compound': 0.4019,\n",
       "  'positive': 0.012,\n",
       "  'negative': 0.006,\n",
       "  'neutral': 0.983}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Etymology and naming\n",
    "The origin of the English word 'cat', Old English catt, is thought to be the Late Latin word cattus, which was first used at the beginning of the 6th century.[20] It was suggested that the word 'cattus' is derived from an Egyptian precursor of Coptic ϣⲁⲩ šau, \"tomcat\", or its feminine form suffixed with -t.[21] The Late Latin word may be derived from another Afro-Asiatic[22] or Nilo-Saharan language. The Nubian word kaddîska \"wildcat\" and Nobiin kadīs are possible sources or cognates.[23] The Nubian word may be a loan from Arabic قَطّ‎ qaṭṭ ~ قِطّ qiṭṭ. It is \"equally likely that the forms might derive from an ancient Germanic word, imported into Latin and thence to Greek and to Syriac and Arabic\".[24] The word may be derived from Germanic and Northern European languages, and ultimately be borrowed from Uralic, cf. Northern Sami gáđfi, \"female stoat\", and Hungarian hölgy, \"stoat\"; from Proto-Uralic *käďwä, \"female (of a furred animal)\".[25]\n",
    "\n",
    "The English puss, extended as pussy and pussycat, is attested from the 16th century and may have been introduced from Dutch poes or from Low German puuskatte, related to Swedish kattepus, or Norwegian pus, pusekatt. Similar forms exist in Lithuanian puižė and Irish puisín or puiscín. The etymology of this word is unknown, but it may have simply arisen from a sound used to attract a cat.[26][27]\n",
    "\n",
    "A male cat is called a tom or tomcat[28] (or a gib,[29] if neutered). An unspayed female is called a queen,[30] especially in a cat-breeding context. A juvenile cat is referred to as a kitten. In Early Modern English, the word kitten was interchangeable with the now-obsolete word catling.[31] A group of cats can be referred to as a clowder or a glaring.[32]\n",
    "'''\n",
    "sentiments=[]\n",
    "sentiment = analyzer.polarity_scores(text)\n",
    "print(sentiment)\n",
    "compound = sentiment[\"compound\"]\n",
    "pos = sentiment[\"pos\"]\n",
    "neu = sentiment[\"neu\"]\n",
    "neg = sentiment[\"neg\"]\n",
    "sentiments.append({\n",
    "            \"text\":text,\n",
    "            \"compound\":compound,\n",
    "            \"positive\":pos,\n",
    "            \"negative\":neg,\n",
    "            \"neutral\":neu\n",
    "})\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
