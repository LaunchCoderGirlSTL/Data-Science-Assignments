{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo before class\n",
    "\n",
    "Install plotly, scipy\n",
    "\n",
    "Start jupyter notebook in chrome?\n",
    "\n",
    "https://towardsdatascience.com/fourier-transformation-and-its-mathematics-fff54a6f6659\n",
    "\n",
    "Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning of class\n",
    "\n",
    "HW review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly.express as px\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('temperatures/temperature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['datetime'], df['Saint Louis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['datetime'], df['Boston'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "Why are the temperature values between 250 and 310? What might you change them to?\n",
    "\n",
    "Why does the data look so noisy?\n",
    "\n",
    "What kinds of things would you like to be able to do to clean up this data?\n",
    "\n",
    "What problems would you like to be able to check for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with missing values in time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df, x='datetime', y='Vancouver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Vancouver'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x is time stamps, xp is x's for existing records, fp is y's for xps\n",
    "x = df['datetime']\n",
    "knowns = df.loc[~df['Vancouver'].isnull(), ['datetime','Vancouver']]\n",
    "xp = knowns['datetime']\n",
    "fp = np.array(knowns['Vancouver'])\n",
    "\n",
    "test = pd.DataFrame({'datetime':x, 'Vancouver': np.interp(x, xp, fp)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(test, x='datetime', y='Vancouver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "What else could you do to address missing values, especially if they were frequent and evenly distributed?\n",
    "\n",
    "When might it be a bad idea to use the np.interp function, and what other options might you have? (Hint: check out the scipy interpolation functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Fourier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,100,1)\n",
    "y = np.sin(x/3)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd = np.abs(np.fft.rfft(y))\n",
    "freqs = np.fft.rfftfreq(len(y))\n",
    "plt.plot(freqs, psd)\n",
    "plt.axvline(1/(6*np.pi), c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion/exploration\n",
    "\n",
    "Try changing the period of the sine fuction.\n",
    "\n",
    "Try adding multiple sine functions of different periods together - what happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier analysis applied to real data; Welch's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd = np.abs(np.fft.rfft(test['Vancouver']))\n",
    "fs = np.fft.rfftfreq(len(test['Vancouver']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fs, psd)\n",
    "plt.axvline(x=1/24, c='red')\n",
    "plt.axvline(x=1/(24*365), c='red')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, psd = signal.welch(test['Vancouver'], nperseg=10000, window='hann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fs, psd)\n",
    "plt.axvline(x=1/24, c='red')\n",
    "plt.axvline(x=1/(24*365), c='red')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion/exploration\n",
    "\n",
    "What are the advantages/disadvantages to making the \"nperseg\" in welch's method smaller or larger?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling Windows and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']=df['datetime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df.groupby('date').agg({'Vancouver':'mean'}).reset_index(), x='date', y='Vancouver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['Vancouver'].rolling(1000).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "Use the rolling() method to find a measure of variance in the data instead of the mean. Check out the pandas rolling documentation to get a sense of what other functions you could use if you wanted to.\n",
    "\n",
    "Pick a coastal city and a midwestern city to compare the variance by plotting the time series charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential smoothing/exponential moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_boston = np.zeros(len(df)-1)\n",
    "\n",
    "factor = 0.1\n",
    "\n",
    "for k in range(len(df)-1):\n",
    "    if k == 0:\n",
    "        smoothed_boston[k]=df.iloc[1]['Boston']\n",
    "    else:\n",
    "        current_data = df.iloc[k]['Boston']\n",
    "        if np.isnan(current_data):\n",
    "            smoothed_boston[k]=smoothed_boston[k-1]\n",
    "        else:\n",
    "            smoothed_boston[k] = (1-factor)*smoothed_boston[k-1] + factor*current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['Boston'], label='orig')\n",
    "plt.plot(smoothed_boston, label='smoothed')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "Why is this called \"exponential\"? (Try writing out what the first few terms work out to be)\n",
    "\n",
    "What happens if you make the \"factor\" in the code much smaller? Try .01, .001.\n",
    "\n",
    "Do you expect this to be faster or slower than implementing a rolling average?\n",
    "\n",
    "Try running the two methods - you can even use the time module to measure performance.  Which method is faster?\n",
    "\n",
    "In applications where you want to smooth data as it arrives in real time, it's very common to use exponential smoothing instead of a rolling average - why do you think this might be?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
